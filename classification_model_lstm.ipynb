{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from nostril import ng\n",
    "from nostril import nonsense_detector as nd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def get_data():\n",
    "  engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "  engine = create_engine(engine_name)\n",
    "\n",
    "  query_sql = \"SELECT * FROM fb_data\"\n",
    "  df = pd.read_sql_query(query_sql, con=engine)\n",
    "  return df\n",
    "\n",
    "def process_text(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    text = TAG_RE.sub('',text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def map_label_to_class(label):\n",
    "  SOURCES = {\n",
    "      0: [\"nytimes\",\"cnn\",\"nbc\"],\n",
    "      1: [\"FoxNews\",\"DailyMail\",\"NYPost\"],\n",
    "      2: [\"bbcnews\",\"Reuters\",\"APNews\"]\n",
    "    }\n",
    "\n",
    "  for class_label, sources in SOURCES.items():\n",
    "      if label in sources:\n",
    "          return class_label\n",
    "  raise ValueError(f\"Label '{label}' not found in any source categories.\")\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "  df['text'] = df['text'].apply(process_text)\n",
    "  df['source'] = df['source'].apply(map_label_to_class)\n",
    "  df.drop(columns=['id'])\n",
    "\n",
    "  label_counts = df['source'].value_counts().sort_index()\n",
    "  plt.bar(label_counts.index, label_counts.values, color=['blue', 'red', 'green'])\n",
    "  plt.xticks(label_counts.index, ['left', 'right', 'center'])  \n",
    "  plt.xlabel('Label')\n",
    "  plt.ylabel('Count')\n",
    "  plt.title('Count of Labels')\n",
    "  plt.show()\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset initialization\n",
    "class FBData(Dataset):\n",
    "  def __init__(self,df):\n",
    "\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    def yield_tokens(data_iter):\n",
    "      for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(df['text']), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    \n",
    "    df.drop(columns=['id'])\n",
    "    \n",
    "    self.data = df\n",
    "    self.vocab = vocab\n",
    "    self.tokenizer = tokenizer\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    text = self.data['text'][idx]\n",
    "    label = self.data['source'][idx]\n",
    "\n",
    "    tokenized_text = self.vocab(self.tokenizer(text))\n",
    "\n",
    "    return torch.tensor(tokenized_text),torch.tensor(label)\n",
    "\n",
    "def collate_batch(batch):\n",
    "  text_list=[]\n",
    "  label_list=[]\n",
    "  for text,label in batch:\n",
    "    text_list.append(text)\n",
    "    label_list.append(label)\n",
    "\n",
    "  padded_texts = pad_sequence(text_list,batch_first=True,padding_value=0)\n",
    "  return padded_texts, torch.tensor(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class BiasClassificationModel(nn.Module):\n",
    "  def __init__(self,vocab_size,embed_dim,hidden_dim,num_layers,num_class,dropout):\n",
    "    super(BiasClassificationModel,self).__init__()\n",
    "    self.embedding = nn.EmbeddingBag(vocab_size,embed_dim,sparse=False)\n",
    "    self.lstm = nn.LSTM(embed_dim, hidden_dim,num_layers,batch_first=True,dropout=dropout)\n",
    "    self.fc = nn.Linear(hidden_dim,num_class)\n",
    "    self.softmax = nn.Softmax(dim=0)\n",
    "  \n",
    "  def forward(self,text):\n",
    "    embedded = self.embedding(text)\n",
    "    lstm_out, (hn, cn) = self.lstm(embedded)\n",
    "    output = self.fc(lstm_out[-1])\n",
    "    return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "def split_data(dataset,batch_size):\n",
    "  train_idx, test_idx = train_test_split(range(len(dataset)),test_size=0.2,random_state=42,shuffle=True)\n",
    "  train_dataset = Subset(dataset,train_idx)\n",
    "  test_dataset = Subset(dataset,test_idx)\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "def train(dataloader,model,optimizer,criterion,verbose):\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  train_acc = 0\n",
    "  total_samples = 0\n",
    "\n",
    "  for text,label in tqdm(dataloader, disable=not verbose):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(text).unsqueeze(0)\n",
    "    loss = criterion(output,label)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_acc += (output.argmax(1) == label).sum().item()\n",
    "    total_samples += text.size(0)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  train_loss/=total_samples\n",
    "  train_acc/=total_samples\n",
    "\n",
    "  return train_loss, train_acc, model, optimizer, criterion\n",
    "\n",
    "def test(dataloader,model,criterion, verbose):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  test_acc = 0\n",
    "  total_samples = 0\n",
    "  test_preds = []\n",
    "  test_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for text,label in tqdm(dataloader,disable=not verbose):\n",
    "      output = model(text).unsqueeze(0)\n",
    "      loss = criterion(output,label)\n",
    "\n",
    "      test_loss += loss.item()\n",
    "      test_acc += (output.argmax(1) == label).sum().item()\n",
    "      total_samples += text.size(0)\n",
    "\n",
    "      test_preds.extend(output.argmax(1).cpu().numpy())\n",
    "      test_labels.extend(label.cpu().numpy())\n",
    "      \n",
    "  test_loss/=total_samples\n",
    "  test_acc/=total_samples\n",
    "  return test_loss,test_acc, test_preds, test_labels\n",
    "\n",
    "def train_test_loop(train_loader,test_loader,num_epochs,model,optimizer,criterion,verbose):\n",
    "  print('Training Starting')\n",
    "\n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  test_losses = []\n",
    "  test_accs = []\n",
    "  for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, model, optimizer, criterion = train(train_loader,model,optimizer,criterion,verbose)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    if verbose: print(f'Training Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "\n",
    "    test_loss, test_acc, test_preds, test_labels  = test(test_loader,model,criterion,verbose)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    if verbose: print(f'Test Epoch [{epoch + 1}/{num_epochs}], Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}')\n",
    "  \n",
    "  print('Training Done, Final Testing Results Are As Shown:')\n",
    "\n",
    "  print(f'Training Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "  print(f'Test Epoch [{epoch + 1}/{num_epochs}], Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}')\n",
    "\n",
    "  plt.plot(train_losses,label='Train Loss')\n",
    "  plt.plot(test_losses,label='Test Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(train_accs,label='Train Acc')\n",
    "  plt.plot(test_accs,label='Test Acc')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy %')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  cm = confusion_matrix(test_preds, test_labels)\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2])\n",
    "  disp.plot(cmap='Blues')\n",
    "  plt.title('Confusion Matrix: Predicted vs Actual Labels')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text,dataset,model):\n",
    "  text = process_text(text)\n",
    "  tokenized_text = dataset.vocab(dataset.tokenizer(text))\n",
    "  tokenized_text = torch.tensor(tokenized_text)\n",
    "\n",
    "  tokenized_text = tokenized_text.unsqueeze(0)\n",
    "\n",
    "  output = model(tokenized_text).unsqueeze(0)\n",
    "  prediction = output.argmax(1).item()\n",
    "\n",
    "  if prediction == 0:\n",
    "    prediction = 'left'\n",
    "  elif prediction == 1:\n",
    "    prediction = 'right'\n",
    "  elif prediction == 2:\n",
    "    prediction = 'center'\n",
    "  else:\n",
    "    raise ValueError(f\"Prediction error.\")\n",
    "\n",
    "  print(f'The text provided leans towards the {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 116/853 [00:01<00:12, 60.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[541], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     predict_text(text,dataset,model)\n\u001b[0;32m     28\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBreaking News: Hersh Goldberg-Polin, an American-Israeli who had been held in Gaza by Hamas for nearly 11 months, died in captivity, President Biden announced.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[541], line 23\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(text, batch_size, num_epochs, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     21\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrain_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     26\u001b[0m   predict_text(text,dataset,model)\n",
      "Cell \u001b[1;32mIn[539], line 58\u001b[0m, in \u001b[0;36mtrain_test_loop\u001b[1;34m(train_loader, test_loader, num_epochs, model, optimizer, criterion, verbose)\u001b[0m\n\u001b[0;32m     56\u001b[0m test_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 58\u001b[0m   train_loss, train_acc, model, optimizer, criterion \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     60\u001b[0m   train_accs\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[1;32mIn[539], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer, criterion, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m   total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m   loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m   \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mtotal_samples\n\u001b[0;32m     22\u001b[0m train_acc\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mtotal_samples\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:392\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    391\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 392\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    395\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(text,batch_size,num_epochs,verbose):\n",
    "\n",
    "  if nd.nonsense(text):\n",
    "    raise Exception(\"Gibberish Text Detected\") \n",
    "\n",
    "  df = get_data()\n",
    "  df = process_data(df)\n",
    "  \n",
    "  dataset = FBData(df)\n",
    "  train_loader, test_loader = split_data(dataset,batch_size)\n",
    "\n",
    "  vocab_size = len(dataset.vocab)\n",
    "  embed_dim = 512\n",
    "  hidden_dim = 64\n",
    "  num_layers = 2\n",
    "  num_classes = 3\n",
    "  dropout = 0.2\n",
    "\n",
    "  model = BiasClassificationModel(vocab_size,embed_dim,hidden_dim,num_layers,num_classes,dropout)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  train_test_loop(train_loader,test_loader,num_epochs,model,optimizer,criterion,verbose)\n",
    "\n",
    "  if(text is not None):\n",
    "    predict_text(text,dataset,model)\n",
    "\n",
    "text = \"Breaking News: Hersh Goldberg-Polin, an American-Israeli who had been held in Gaza by Hamas for nearly 11 months, died in captivity, President Biden announced.\"\n",
    "main(text,batch_size=1,num_epochs=10,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
