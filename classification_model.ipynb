{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from nostril import nonsense_detector as nd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def get_data():\n",
    "  engine_name = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "  engine = create_engine(engine_name)\n",
    "\n",
    "  query_sql = \"SELECT * FROM fb_data\"\n",
    "  df = pd.read_sql_query(query_sql, con=engine)\n",
    "  return df\n",
    "\n",
    "def process_text(text):\n",
    "  TAG_RE = re.compile(r'<[^>]+>')\n",
    "  text = TAG_RE.sub('',text)\n",
    "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "  text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "  return simple_preprocess(text, deacc=True)\n",
    "\n",
    "def map_label_to_class(label):\n",
    "  SOURCES = {\n",
    "    0: [\"nytimes\",\"cnn\",\"nbc\"],\n",
    "    1: [\"FoxNews\",\"DailyMail\",\"NYPost\"],\n",
    "    2: [\"bbcnews\",\"Reuters\",\"APNews\"]\n",
    "  }\n",
    "\n",
    "  for class_label, sources in SOURCES.items():\n",
    "      if label in sources:\n",
    "          return class_label\n",
    "  raise ValueError(f\"Label '{label}' not found in any source categories.\")\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "  df['text'] = df['text'].apply(process_text)\n",
    "  df['source'] = df['source'].apply(map_label_to_class)\n",
    "  df.drop(columns=['id'])\n",
    "\n",
    "  label_counts = df['source'].value_counts().sort_index()\n",
    "  plt.bar(label_counts.index, label_counts.values, color=['blue', 'red', 'green'])\n",
    "  plt.xticks(label_counts.index, ['left', 'right', 'center'])  \n",
    "  plt.xlabel('Label')\n",
    "  plt.ylabel('Count')\n",
    "  plt.title('Count of Labels')\n",
    "  plt.show()\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc 2 vec\n",
    "def create_d2v(df):\n",
    "  print('Training doc2vec model')\n",
    "  tagged =  [TaggedDocument(words=text, tags=[str(i)]) for i, text in enumerate(df['text'])]\n",
    "  d2v_model = Doc2Vec(dm=1,vector_size=100,window=2,min_count=1,workers=4,epochs=20)\n",
    "  d2v_model.build_vocab(tagged)\n",
    "  d2v_model.train(utils.shuffle(tagged),total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "  print('Finished Training!!!')\n",
    "  return d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset initialization\n",
    "class FBData(Dataset):\n",
    "  def __init__(self,df,d2v_model):\n",
    "    df.drop(columns=['id'])\n",
    "    \n",
    "    self.data = df\n",
    "    self.d2v = d2v_model\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    text = self.data['text'][idx]\n",
    "    label = self.data['source'][idx]\n",
    "    vectorized_text = self.d2v.infer_vector(text)\n",
    "    return torch.tensor(vectorized_text),torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class BiasClassificationModel(nn.Module):\n",
    "  def __init__(self,input_size,hidden_dim_1,hidden_dim_2,num_class):\n",
    "    super(BiasClassificationModel,self).__init__()\n",
    "    self.fc1 = nn.Linear(input_size,hidden_dim_1)\n",
    "    self.fc2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "    self.fc3 = nn.Linear(hidden_dim_2,num_class)\n",
    "    self.activation = nn.ReLU()\n",
    "    self.softmax = nn.Softmax(dim=0)\n",
    "  \n",
    "  def forward(self,text):\n",
    "    output = self.activation(self.fc1(text))\n",
    "    output = self.activation(self.fc2(output))\n",
    "    output = self.activation(self.fc3(output))\n",
    "    return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "def split_data(dataset,batch_size):\n",
    "  train_idx, test_idx = train_test_split(range(len(dataset)),test_size=0.2,random_state=42,shuffle=True)\n",
    "  train_dataset = Subset(dataset,train_idx)\n",
    "  test_dataset = Subset(dataset,test_idx)\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "def train(dataloader,model,optimizer,criterion,verbose):\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  train_acc = 0\n",
    "  total_samples = 0\n",
    "\n",
    "  for text,label in tqdm(dataloader, disable=not verbose):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(text)\n",
    "    loss = criterion(output,label)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    train_acc += (output.argmax(1) == label).sum().item()\n",
    "    total_samples += text.size(0)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  train_loss/=total_samples\n",
    "  train_acc/=total_samples\n",
    "\n",
    "  return train_loss, train_acc, model, optimizer, criterion\n",
    "\n",
    "def test(dataloader,model,criterion, verbose):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  test_acc = 0\n",
    "  total_samples = 0\n",
    "  test_preds = []\n",
    "  test_labels = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for text,label in tqdm(dataloader,disable=not verbose):\n",
    "      output = model(text)\n",
    "      loss = criterion(output,label)\n",
    "\n",
    "      test_loss += loss.item()\n",
    "      test_acc += (output.argmax(1) == label).sum().item()\n",
    "      total_samples += text.size(0)\n",
    "\n",
    "      test_preds.extend(output.argmax(1).cpu().numpy())\n",
    "      test_labels.extend(label.cpu().numpy())\n",
    "      \n",
    "  test_loss/=total_samples\n",
    "  test_acc/=total_samples\n",
    "  return test_loss,test_acc, test_preds, test_labels\n",
    "\n",
    "def train_test_loop(train_loader,test_loader,num_epochs,model,optimizer,criterion,verbose):\n",
    "  print('Training Starting')\n",
    "\n",
    "  train_losses = []\n",
    "  train_accs = []\n",
    "  test_losses = []\n",
    "  test_accs = []\n",
    "  for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, model, optimizer, criterion = train(train_loader,model,optimizer,criterion,verbose)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    if verbose: print(f'Training Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "\n",
    "    test_loss, test_acc, test_preds, test_labels  = test(test_loader,model,criterion,verbose)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    if verbose: print(f'Test Epoch [{epoch + 1}/{num_epochs}], Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}')\n",
    "  \n",
    "  print('Training Done, Final Testing Results Are As Shown:')\n",
    "\n",
    "  print(f'Training Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "  print(f'Test Epoch [{epoch + 1}/{num_epochs}], Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}')\n",
    "\n",
    "  plt.plot(train_losses,label='Train Loss')\n",
    "  plt.plot(test_losses,label='Test Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(train_accs,label='Train Acc')\n",
    "  plt.plot(test_accs,label='Test Acc')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy %')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  cm = confusion_matrix(test_preds, test_labels)\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2])\n",
    "  disp.plot(cmap='Blues')\n",
    "  plt.title('Confusion Matrix: Predicted vs Actual Labels')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text,model,d2v_model):\n",
    "  tokenized_text = process_text(text)\n",
    "  vectorized_text = d2v_model.infer_vector(tokenized_text)\n",
    "  output = model(vectorized_text)\n",
    "  prediction = output.argmax(1).item()\n",
    "\n",
    "  if prediction == 0:\n",
    "    prediction = 'left'\n",
    "  elif prediction == 1:\n",
    "    prediction = 'right'\n",
    "  elif prediction == 2:\n",
    "    prediction = 'center'\n",
    "  else:\n",
    "    raise ValueError(f\"Prediction error.\")\n",
    "\n",
    "  print(f'The text provided leans towards the {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training doc2vec model\n",
      "Finished Training!!!\n",
      "100\n",
      "Training Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:01<00:00, 249.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/10], Loss: 0.5398, Accuracy: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 387.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [1/10], Loss: 0.5327, Accuracy: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:02<00:00, 247.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [2/10], Loss: 0.5295, Accuracy: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 383.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [2/10], Loss: 0.5230, Accuracy: 0.4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:02<00:00, 224.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [3/10], Loss: 0.5150, Accuracy: 0.4778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 373.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [3/10], Loss: 0.5176, Accuracy: 0.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:02<00:00, 223.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [4/10], Loss: 0.5206, Accuracy: 0.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 309.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [4/10], Loss: 0.5228, Accuracy: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:02<00:00, 239.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch [5/10], Loss: 0.5255, Accuracy: 0.4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:00<00:00, 389.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [5/10], Loss: 0.5217, Accuracy: 0.4516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 436/495 [00:01<00:00, 254.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[188], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     predict_text(text,dataset,model,d2v_model)\n\u001b[0;32m     27\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBreaking News: Hersh Goldberg-Polin, an American-Israeli who had been held in Gaza by Hamas for nearly 11 months, died in captivity, President Biden announced.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[188], line 22\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(text, batch_size, num_epochs, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mtrain_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     25\u001b[0m   predict_text(text,dataset,model,d2v_model)\n",
      "Cell \u001b[1;32mIn[186], line 58\u001b[0m, in \u001b[0;36mtrain_test_loop\u001b[1;34m(train_loader, test_loader, num_epochs, model, optimizer, criterion, verbose)\u001b[0m\n\u001b[0;32m     56\u001b[0m test_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 58\u001b[0m   train_loss, train_acc, model, optimizer, criterion \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     60\u001b[0m   train_accs\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[1;32mIn[186], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer, criterion, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m   total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m   loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m   \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m train_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mtotal_samples\n\u001b[0;32m     22\u001b[0m train_acc\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mtotal_samples\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    372\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 373\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\autograd\\profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\.Work\\projects\\Media-Bias-Detector\\.venv\\Lib\\site-packages\\torch\\_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(text,batch_size,num_epochs,verbose):\n",
    "\n",
    "  if nd.nonsense(text):\n",
    "    raise Exception(\"Gibberish Text Detected\") \n",
    "  \n",
    "  df = get_data()\n",
    "  df = process_data(df)\n",
    "  d2v_model = create_d2v(df)\n",
    "  dataset = FBData(df,d2v_model)\n",
    "  train_loader, test_loader = split_data(dataset,batch_size)\n",
    "\n",
    "  input_size = d2v_model.vector_size\n",
    "  print(input_size)\n",
    "  hidden_dim_1 = 64\n",
    "  hidden_dim_2 = 32\n",
    "  num_classes = 3\n",
    "\n",
    "  model = BiasClassificationModel(input_size,hidden_dim_1,hidden_dim_2,num_classes)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  train_test_loop(train_loader,test_loader,num_epochs,model,optimizer,criterion,verbose)\n",
    "\n",
    "  if(text is not None):\n",
    "    predict_text(text,dataset,model,d2v_model)\n",
    "\n",
    "text = \"Breaking News: Hersh Goldberg-Polin, an American-Israeli who had been held in Gaza by Hamas for nearly 11 months, died in captivity, President Biden announced.\"\n",
    "main(text,batch_size=2,num_epochs=10,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
